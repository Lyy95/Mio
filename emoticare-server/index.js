const express = require('express');
const cors = require('cors');
const dotenv = require('dotenv');
const { OpenAI } = require('openai');
const { createClient } = require('@supabase/supabase-js');

// Load env vars
dotenv.config();

const app = express();
const PORT = process.env.PORT || 5000;

// Init Supabase
const supabaseUrl = process.env.SUPABASE_URL;
const supabaseKey = process.env.SUPABASE_KEY;
const supabase = (supabaseUrl && supabaseKey && supabaseUrl !== 'https://your-project.supabase.co') 
  ? createClient(supabaseUrl, supabaseKey) 
  : null;

if (!supabase) {
  console.log('âš ï¸ Supabase config missing. Chat history will NOT be saved.');
}

// Middleware
app.use(cors());
app.use(express.json());

// Init OpenAI (Connect to Zhipu GLM)
const openai = process.env.GLM_API_KEY 
  ? new OpenAI({ 
      apiKey: process.env.GLM_API_KEY,
      baseURL: "https://open.bigmodel.cn/api/paas/v4/" // GLM API Endpoint
    })
  : null;

// Routes
app.get('/', (req, res) => {
  res.send('EmotiCare API is running ðŸš€');
});

app.post('/api/chat', async (req, res) => {
  const { message } = req.body;

  if (!message) {
    return res.status(400).json({ error: 'Message is required' });
  }

  try {
    let reply;

    if (openai) {
      // Real AI Response via GLM
      try {
        const completion = await openai.chat.completions.create({
          messages: [
            { role: "system", content: "ä½ å« EmotiCareï¼Œæ˜¯ä¸€ä¸ªæ¸©æš–ã€çœŸå®žã€ç¨å¾®å¸¦ç‚¹å¹½é»˜æ„Ÿçš„æœ‹å‹ã€‚ä½ çš„ç›®æ ‡æ˜¯æä¾›æƒ…ç»ªä»·å€¼å’Œå»ºè®®ã€‚æ‹’ç»è¯´æ•™ï¼Œæ‹’ç»çˆ¹å‘³ï¼Œæ‹’ç»è™šå‡çš„é¸¡æ±¤ã€‚ç”¨ç®€æ´ã€å£è¯­åŒ–çš„ä¸­æ–‡å›žç­”ã€‚å¦‚æžœç”¨æˆ·æŠ±æ€¨ç´¯ï¼Œå°±é™ªä»–ä¸€èµ·åæ§½ï¼›å¦‚æžœç”¨æˆ·æ±‚å®‰æ…°ï¼Œå°±ç»™ä»–ä¸€ä¸ªäº‘æ‹¥æŠ±ã€‚" },
            { role: "user", content: message }
          ],
          model: "glm-4", // GLM Model
          temperature: 0.7,
        });
        reply = completion.choices[0].message.content;
      } catch (err) {
        console.error('GLM API Failed:', err.message);
        console.log('âš ï¸ Falling back to mock response due to API error.');
        reply = "AI å¥½åƒåœ¨æ‰“ç›¹ï¼ˆAPI æŠ¥é”™ï¼‰ï¼Œä½†æˆ‘è¿˜åœ¨ã€‚è¦ä¸ä½ å…ˆå–æ¯æ°´ä¼‘æ¯ä¸‹ï¼ŸðŸ¥¤";
      }
    } else {
      // Mock Response (Fallback)
      console.log('âš ï¸ No OpenAI Key found, using mock response.');
      const mockReplies = [
        "å”‰ï¼Œè¿™ç¡®å®žæŒºçƒ¦äººçš„ã€‚è¦ä¸å…ˆæŠŠæ‰‹å¤´çš„äº‹æ”¾ä¸€æ”¾ï¼ŒåŽ»æ¥¼ä¸‹ä¾¿åˆ©åº—ä¹°ç“¶å¿«ä¹æ°´ï¼ŸðŸ¥¤",
        "å¤ªçœŸå®žäº†ï¼Œæˆ‘ä¹Ÿç»å¸¸æœ‰è¿™ç§æ„Ÿè§‰ã€‚è¿™ç§æ—¶å€™å°±åˆ«é€¼è‡ªå·±äº†ï¼Œå…è®¸è‡ªå·±æ‘†çƒ‚ä¸€ä¼šå„¿ä¹Ÿæ²¡äº‹ã€‚",
        "è¿™ç§ç ´äº‹è°é‡åˆ°éƒ½ä¼šç‚¸æ¯›çš„ã€‚ä½ å·²ç»å¿å¾—å¾ˆå¥½äº†ï¼Œæƒ³éª‚å°±éª‚ä¸¤å¥å§ã€‚",
        "å·¥ä½œæ˜¯åšä¸å®Œçš„ï¼Œèº«ä½“æ˜¯è‡ªå·±çš„ã€‚å¬æˆ‘çš„ï¼Œå“ªæ€•å°±ååˆ†é’Ÿï¼ŒæŠŠæ‰‹æœºæ‰”è¿œç‚¹ï¼Œé—­çœ¼èººä¼šå„¿ã€‚",
        "æ„Ÿè§‰ä½ çŽ°åœ¨åƒä¸ªé«˜åŽ‹é”…ã€‚è¦ä¸è¦åŽ»æ´—æŠŠè„¸é™é™æ¸©ï¼Ÿæˆ–è€…åƒé¡¿å¥½çš„å‘æ³„ä¸€ä¸‹ï¼Ÿ"
      ];
      reply = mockReplies[Math.floor(Math.random() * mockReplies.length)];
    }

    // Save to Supabase (if configured)
    if (supabase) {
      console.log('Attempting to save to Supabase...');
      const { error } = await supabase
        .from('messages')
        .insert([
          { role: 'user', content: message, created_at: new Date() },
          { role: 'ai', content: reply, created_at: new Date() }
        ]);
      
      if (error) {
        console.error('âŒ Supabase Save Error:', error.message);
        console.error('Error Details:', error);
      } else {
        console.log('âœ… Chat saved to Supabase successfully');
      }
    }

    res.json({ reply });

  } catch (error) {
    console.error('AI Error:', error);
    res.status(500).json({ error: 'Failed to generate response' });
  }
});

// Start Server
app.listen(PORT, () => {
  console.log(`âœ… Server running on http://localhost:${PORT}`);
});
